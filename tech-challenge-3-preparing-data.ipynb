{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Girls Ballet Tutu Neon Pink</td>\n",
       "      <td>High quality 3 layer ballet tutu. 12 inches in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult Ballet Tutu Yellow</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Way Things Work: An Illustrated Encycloped...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mog's Kittens</td>\n",
       "      <td>Judith Kerr&amp;#8217;s best&amp;#8211;selling adventu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Misty of Chincoteague</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hilda Boswell's treasury of children's stories...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Simple Truths of Service: Inspired by John...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Girls Ballet Tutu Neon Blue</td>\n",
       "      <td>Dance tutu for girls ages 2-8 years. Perfect f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Evaluating Research in Academic Journals - A P...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Seuss ABC (Dr.Seuss Classic Collection) (S...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Noddy Story Book Treasury</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Book of Daniel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                         Girls Ballet Tutu Neon Pink   \n",
       "1                            Adult Ballet Tutu Yellow   \n",
       "2   The Way Things Work: An Illustrated Encycloped...   \n",
       "3                                       Mog's Kittens   \n",
       "4                               Misty of Chincoteague   \n",
       "5   Hilda Boswell's treasury of children's stories...   \n",
       "6   The Simple Truths of Service: Inspired by John...   \n",
       "7                         Girls Ballet Tutu Neon Blue   \n",
       "8   Evaluating Research in Academic Journals - A P...   \n",
       "9   Dr. Seuss ABC (Dr.Seuss Classic Collection) (S...   \n",
       "10                          Noddy Story Book Treasury   \n",
       "11                                 The Book of Daniel   \n",
       "\n",
       "                                              content  \n",
       "0   High quality 3 layer ballet tutu. 12 inches in...  \n",
       "1                                                      \n",
       "2                                                      \n",
       "3   Judith Kerr&#8217;s best&#8211;selling adventu...  \n",
       "4                                                      \n",
       "5                                                      \n",
       "6                                                      \n",
       "7   Dance tutu for girls ages 2-8 years. Perfect f...  \n",
       "8                                                      \n",
       "9                                                      \n",
       "10                                                     \n",
       "11                                                     "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dados = pd.read_json(\"trn.json\",lines=True)\n",
    "\n",
    "dados = dados.drop(columns=['target_ind','target_rel','uid'])\n",
    "\n",
    "dados.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2248619 entries, 0 to 2248618\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Dtype \n",
      "---  ------   ----- \n",
      " 0   title    object\n",
      " 1   content  object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2248619 entries, 0 to 2248618\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Dtype \n",
      "---  ------   ----- \n",
      " 0   title    string\n",
      " 1   content  string\n",
      "dtypes: string(2)\n",
      "memory usage: 34.3 MB\n"
     ]
    }
   ],
   "source": [
    "dados['title'] = dados['title'].astype('string')\n",
    "dados['content'] = dados['content'].astype('string')\n",
    "\n",
    "\n",
    "dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 1. Remover linhas vazias\n",
    "df = dados.dropna(subset=['title', 'content'])\n",
    "df = df[(df['title'].str.strip() != \"\") & (df['content'].str.strip() != \"\")]\n",
    "\n",
    "# 2. Normalizar texto\n",
    "# dados['title'] = dados['title'].str.lower().str.strip()\n",
    "# dados['content'] = dados['content'].str.lower().str.strip()\n",
    "\n",
    "# 3. Remover caracteres especiais\n",
    "def limpar_texto(texto):\n",
    "    texto = re.sub(r\"http\\S+|www\\S+\", \"\", texto)  # Remove URLs\n",
    "    # texto = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", texto)  # Remove caracteres especiais\n",
    "    return texto.strip()\n",
    "\n",
    "df['title'] = df['title'].apply(limpar_texto)\n",
    "df['content'] = df['content'].apply(limpar_texto)\n",
    "\n",
    "# 4. Remover duplicatas\n",
    "df = df.drop_duplicates(subset=['title', 'content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1367051 entries, 0 to 2248618\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count    Dtype \n",
      "---  ------   --------------    ----- \n",
      " 0   title    1367051 non-null  object\n",
      " 1   content  1367051 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/unslothai/unsloth.git\n",
      "  Cloning https://github.com/unslothai/unsloth.git to c:\\users\\hahhf\\appdata\\local\\temp\\pip-req-build-rxxfvorx\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit 4cbebe151d9c8f813e4e69be1d86a5657a44ee60\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: unsloth\n",
      "  Building wheel for unsloth (pyproject.toml): started\n",
      "  Building wheel for unsloth (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for unsloth: filename=unsloth-2024.12.2-py3-none-any.whl size=169006 sha256=2f982754d5d9cc3f249c913ae1fd1810229d283e4a3b6c40ec3673d35e9cc7ae\n",
      "  Stored in directory: C:\\Users\\hahhf\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-_6z_1de0\\wheels\\d1\\17\\05\\850ab10c33284a4763b0595cd8ea9d01fce6e221cac24b3c01\n",
      "Successfully built unsloth\n",
      "Installing collected packages: unsloth\n",
      "Successfully installed unsloth-2024.12.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping unsloth as it is not installed.\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git 'C:\\Users\\hahhf\\AppData\\Local\\Temp\\pip-req-build-rxxfvorx'\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\hahhf\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.0-py3-none-win_amd64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\hahhf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bitsandbytes) (2.3.1+cu118)\n",
      "Requirement already satisfied: numpy in c:\\users\\hahhf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bitsandbytes) (1.26.3)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in c:\\users\\hahhf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hahhf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->bitsandbytes) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\hahhf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hahhf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hahhf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hahhf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->bitsandbytes) (2024.2.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\hahhf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch->bitsandbytes) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\hahhf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->bitsandbytes) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\hahhf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->bitsandbytes) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hahhf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hahhf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Downloading bitsandbytes-0.45.0-py3-none-win_amd64.whl (68.5 MB)\n",
      "   ---------------------------------------- 0.0/68.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/68.5 MB 640.0 kB/s eta 0:01:48\n",
      "    --------------------------------------- 1.6/68.5 MB 20.1 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 3.6/68.5 MB 28.8 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 11.3/68.5 MB 108.8 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 14.6/68.5 MB 131.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 17.8/68.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 21.2/68.5 MB 72.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 24.6/68.5 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 28.1/68.5 MB 73.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 31.7/68.5 MB 73.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 35.2/68.5 MB 73.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 38.7/68.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 42.1/68.5 MB 72.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 45.7/68.5 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 49.5/68.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 53.5/68.5 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 57.5/68.5 MB 81.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 61.6/68.5 MB 93.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 65.9/68.5 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  68.5/68.5 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 68.5/68.5 MB 59.4 MB/s eta 0:00:00\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\hahhf\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement triton (from versions: none)\n",
      "ERROR: No matching distribution found for triton\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\hahhf\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hahhf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\unsloth\\__init__.py:122: UserWarning: Unsloth: Running `ldconfig /usr/lib64-nvidia` to link CUDA.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'triton' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\unsloth\\__init__.py:120\u001b[0m\n\u001b[0;32m    119\u001b[0m     cdequantize_blockwise_fp32 \u001b[38;5;241m=\u001b[39m bnb\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mcdequantize_blockwise_fp32\n\u001b[1;32m--> 120\u001b[0m     \u001b[43mlibcuda_dirs\u001b[49m()\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'libcuda_dirs' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Creating the model utilizing unslothAI\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munsloth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m max_seq_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2048\u001b[39m \u001b[38;5;66;03m# Choose any! We auto support RoPE Scaling internally!\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\unsloth\\__init__.py:146\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    145\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(bnb)\n\u001b[1;32m--> 146\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(\u001b[43mtriton\u001b[49m)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     libcuda_dirs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'triton' is not defined"
     ]
    }
   ],
   "source": [
    "#Creating the model utilizing unslothAI\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
    "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
    "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
    "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"yahma/alpaca-cleaned\", split = \"train\")\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
